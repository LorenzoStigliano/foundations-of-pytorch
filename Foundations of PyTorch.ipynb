{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Foundations of PyTorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning - algorithms that learn which features matter. Made up of different layers of neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different layers in a network can be used to find different features, layers which we dont interact directly with are the hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuron - has an activation function, any number of inputs (vector of values) and then produces an output of the neuron. The outputs of neuros feed into the neuros from the next layer. Each connection has an assosicted wieght value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the second neuron is sensituve to the output of the first neuron, the connection between them gets stronger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuron:\n",
    "Affine transformation : Wx+b -> max(Wx+b,0) (the activation function) for non linear relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common activation functions: ReLU, logit (logistic sigmoid function), tanh, step, softmax(0,1) output is a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensor Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central unit of data in PyTorch. A tensor consists of a set of primitive values shaped into an arry of any number of dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectos are 1-D tensors [1,2,3]\n",
    "Tensors are N-D tensors [[1,2][1,2]]\n",
    "They are numpy arrays that have the ability to be executed on GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base datatype of a Tensor and changing the datatype for tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_default_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Creating and Initializing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_arr = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "tensor_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_tensor(tensor_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.numel(tensor_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.1168e+169, 2.8793e+180],\n",
       "        [3.4667e+179,  1.7714e-51]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_uninitialized = torch.Tensor(2,2)\n",
    "tensor_uninitialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8388, 0.2903],\n",
       "        [0.4427, 0.8309]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_initialized = torch.rand(2,2)\n",
    "tensor_initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_int = torch.tensor([5,3]).type(torch.IntTensor)\n",
    "tensor_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int16)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_short = torch.ShortTensor([1.0,2.0,3.0])\n",
    "tensor_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 3.], dtype=torch.float16)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float = torch.tensor([5,3]).type(torch.half)\n",
    "tensor_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 10., 10., 10., 10., 10.],\n",
       "        [10., 10., 10., 10., 10., 10.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_fill = torch.full((2,6),fill_value=10.0)\n",
    "tensor_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_one = torch.ones((2,4),dtype=torch.int32)\n",
    "tensor_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_zeros = torch.zeros_like(tensor_one)\n",
    "tensor_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_eye = torch.eye(4)\n",
    "tensor_eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 1],\n",
       "        [2, 2],\n",
       "        [3, 3]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Returns coordinates of all non-zero elements in tensor\n",
    "non_zero = torch.nonzero(tensor_eye)\n",
    "non_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = torch.tensor([[0,1,1,],\n",
    "                  [2,2,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor([3,4,5],dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 1, 1],\n",
       "                       [2, 2, 0]]),\n",
       "       values=tensor([3., 4., 5.]),\n",
       "       size=(2, 5), nnz=3, dtype=torch.float32, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_tensor = torch.sparse_coo_tensor(i,v,[2,5])\n",
    "sparse_tensor.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Simple operations with Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3047, 0.0130, 0.5577],\n",
       "        [0.2282, 0.9586, 0.6640]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_tensor = torch.rand(2,3)\n",
    "initial_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 10., 10.],\n",
       "        [10., 10., 10.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Operations that modilfy the tensor in-place have an \"_\" suffix\n",
    "initial_tensor.fill_(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'fill'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-c4ca7a2525cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minitial_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'fill'"
     ]
    }
   ],
   "source": [
    "# Not all tensors have an option for not in place\n",
    "initial_tensor.fill(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15., 15., 15.],\n",
       "        [15., 15., 15.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add() out of place operation and stores result in new tensor\n",
    "new_tensor = initial_tensor.add(5)\n",
    "new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 10., 10.],\n",
       "        [10., 10., 10.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note the initial tensor has not changed since it was not an inplace operation\n",
    "initial_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18., 18., 18.],\n",
       "        [18., 18., 18.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add_() in-place operation\n",
    "initial_tensor.add_(8)\n",
    "initial_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.8730, 3.8730, 3.8730],\n",
       "        [3.8730, 3.8730, 3.8730]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor.sqrt_()\n",
    "new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1000,  0.8071,  1.5143,  2.2214,  2.9286,  3.6357,  4.3429,  5.0500,\n",
       "         5.7571,  6.4643,  7.1714,  7.8786,  8.5857,  9.2929, 10.0000])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uses lots of numpy functions\n",
    "x = torch.linspace(start=0.1,end=10.0,steps=15)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1000, 0.8071, 1.5143, 2.2214, 2.9286]),\n",
       " tensor([3.6357, 4.3429, 5.0500, 5.7571, 6.4643]),\n",
       " tensor([ 7.1714,  7.8786,  8.5857,  9.2929, 10.0000]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the x tensor into 3 parts third variable is the dimension we want to do it in\n",
    "tensor_chunk = torch.chunk(x,3,0)\n",
    "tensor_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.8071, 1.5143, 2.2214, 2.9286, 3.6357, 4.3429, 5.0500, 5.7571,\n",
       "        6.4643, 1.0000, 2.0000, 3.0000])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to join tensors use torch.cat()\n",
    "tensor1 = tensor_chunk[0]\n",
    "tensor2 = tensor_chunk[1]\n",
    "tensor3 = torch.tensor([1,2,3])\n",
    "\n",
    "torch.cat((tensor1,tensor2,tensor3),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.,  8., 30.],\n",
       "        [40.,  5.,  6.],\n",
       "        [12.,  2., 21.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.Tensor([[10,8,30],[40,5,6],[12,2,21]])\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 2., 21.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor[1:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 10.,   8.,  30.,  40.,   5.,   6.,  12.,   2., 100.])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.view() doesnt create a new tensor but shares the same place in memory as the original\n",
    "resized_tensor = random_tensor.view(9)\n",
    "resized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 10.,   8.,  30.,  40.,   5.,   6.,  12.,   2., 100.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change 2,2 in original reuslts in a change in the resized_tensor\n",
    "random_tensor[2,2] = 100.0\n",
    "resized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 10.,   8.,  30.],\n",
       "        [ 40.,   5.,   6.],\n",
       "        [ 12.,   2., 100.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 10.],\n",
       "         [  8.],\n",
       "         [ 30.]],\n",
       "\n",
       "        [[ 40.],\n",
       "         [  5.],\n",
       "         [  6.]],\n",
       "\n",
       "        [[ 12.],\n",
       "         [  2.],\n",
       "         [100.]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change a dimension of a tensor by using squeeze and unsqueeze\n",
    "tensor_unsqueeze = torch.unsqueeze(random_tensor,2)\n",
    "tensor_unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 3])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we have added an extra dimension 3x3x1 now\n",
    "tensor_unsqueeze.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18., 18., 18.],\n",
       "        [18., 18., 18.]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18., 18.],\n",
       "        [18., 18.],\n",
       "        [18., 18.]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_transpose = torch.transpose(initial_tensor,0,1)\n",
    "tensor_transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Elementwise and Matrix operations on Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 10.,   8.,  30.],\n",
       "        [ 40.,   5.,   6.],\n",
       "        [ 12.,   2., 100.]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tensor, sorted_indices = torch.sort(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  8.,  10.,  30.],\n",
       "        [  5.,   6.,  40.],\n",
       "        [  2.,  12., 100.]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 2],\n",
       "        [1, 2, 0],\n",
       "        [1, 0, 2]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1000, -2.2000,  3.3000], dtype=torch.float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float = torch.FloatTensor([-1.1,-2.2,3.3])\n",
    "tensor_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1000, 2.2000, 3.3000], dtype=torch.float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_abs = torch.abs(tensor_float)\n",
    "tensor_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand1 = torch.abs(torch.rand(2,3))\n",
    "rand2 = torch.abs(torch.rand(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9696, 1.8206, 0.3003],\n",
       "        [0.3730, 1.0690, 1.1197]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add = rand1+rand2\n",
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9696, 1.8206, 0.3003],\n",
       "        [0.3730, 1.0690, 1.1197]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add2 = torch.add(rand1,rand2)\n",
    "add2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.Tensor([[-1,-2,-3],[1,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4286, 1.1765, 1.1111],\n",
       "        [0.7692, 0.8696, 0.9091]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_div = torch.div(tensor,tensor+0.3)\n",
    "tensor_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4., 9.],\n",
       "        [1., 4., 9.]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_mul = tensor.mul(tensor)\n",
    "tensor_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2000, -0.2000, -0.2000],\n",
       "        [ 1.0000,  2.0000,  2.0000]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_clamp = torch.clamp(tensor,min=-0.2,max=2)\n",
    "tensor_clamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.Tensor([1,2])\n",
    "t2 = torch.Tensor([10,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(50.)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product = torch.dot(t1,t2)\n",
    "dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = torch.Tensor([[1,2,3],\n",
    "                       [4,5,6]])\n",
    "vector = torch.Tensor([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8., 17.])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_vector = torch.mv(matrix,vector)\n",
    "matrix_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix2 = torch.Tensor([[10,30],[20,0],[50,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[200.,  30.],\n",
       "        [440., 120.]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_mul = torch.mm(matrix,matrix2)\n",
    "matrix_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(matrix_mul,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin(matrix_mul,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Conversion between Pytorch and NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1987, 0.4570, 0.3728],\n",
       "        [0.8298, 0.1654, 0.6824],\n",
       "        [0.9997, 0.6014, 0.1287],\n",
       "        [0.6674, 0.2404, 0.1548]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(4,3)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19870377, 0.45699255, 0.37283333],\n",
       "       [0.8297834 , 0.16538464, 0.68242655],\n",
       "       [0.99968894, 0.60140543, 0.12871409],\n",
       "       [0.66743587, 0.24039005, 0.15483137]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_from_tensor = tensor.numpy()\n",
    "numpy_from_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(numpy_from_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NumPy array and the PyTorch tensor share underlying memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_from_tensor[0,0] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100.0000,   0.4570,   0.3728],\n",
       "        [  0.8298,   0.1654,   0.6824],\n",
       "        [  0.9997,   0.6014,   0.1287],\n",
       "        [  0.6674,   0.2404,   0.1548]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97902889, 0.03794152, 0.75008729],\n",
       "       [0.66736971, 0.40700507, 0.95369863],\n",
       "       [0.08517584, 0.31320742, 0.91102737]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_arr = np.random.rand(3,3)\n",
    "numpy_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_from_numpy = torch.from_numpy(numpy_arr)\n",
    "tensor_from_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array_one = np.array([4,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as_tensor() - Preforms copy of the data is not already a tensor - here since we are not changing the data type or device the new tensor will just use the same memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data is alrwady a tensor with the same dtype and the device then no copy is preformed and a new tensor is returned with the same computational graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To aviod making compies use torch.as_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 8], dtype=torch.int32)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_from_array_one = torch.as_tensor(np_array_one)\n",
    "tensor_from_array_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array_one[1] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5], dtype=torch.int32)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_from_array_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to make a copy, they dont share the same place in memory so changes made in the NumPy array don't change the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array_two = np.array([2,2])\n",
    "np_array_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_from_array_two = torch.tensor(np_array_two)\n",
    "tensor_from_array_two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Support for CUDA devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU - specilized chips with highly parallel architecture that makes them faster than CPUs when trainig models. Usage for GPUs traditionally for videos and graphics and used in Big Data and Machine Learning applications. Speed up of 10-50 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUDA - A parallel computing platform and API, a standard for general purpose user of GPUs. If CUDA-enabled GPUs are availabe the speedup will occur automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Setting up VM to work with GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use google cloud to us a VM to launching GPUs. https://pytorch.org/get-started/cloud-partners/ to deploy the deep learning VM. Then you can ssh into the VM. You will also need the Cloud SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Creating Tensors on CUDA-enabled devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: ALL THE FOLLOWING COMMANDS HAVE TO BE RUN ON A VM THAT HAS CUDA DEVICES.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available() #True in VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-222784030e88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\speck\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36minit\u001b[1;34m()\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[0mDoes\u001b[0m \u001b[0mnothing\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCUDA\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0malready\u001b[0m \u001b[0minitialized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \"\"\"\n\u001b[1;32m--> 158\u001b[1;33m     \u001b[0m_lazy_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\speck\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    184\u001b[0m             raise RuntimeError(\n\u001b[0;32m    185\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             raise AssertionError(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\speck\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[1;34m()\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[0mFound\u001b[0m \u001b[0mno\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0mon\u001b[0m \u001b[0myour\u001b[0m \u001b[0msystem\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mPlease\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myou\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mGPU\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minstalled\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdriver\u001b[0m \u001b[1;32mfrom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m http://www.nvidia.com/Download/index.aspx\"\"\")\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;31m# TODO: directly link to the alternative bin that needs install\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: \nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "torch.cuda.init()\n",
    "torch.cuda.current_device() #device it is using\n",
    "torch.cuda.device_count() #number of devices used\n",
    "torch.cuda.memeory_allocated()\n",
    "torch.cuda.memory_cached() \n",
    "\n",
    "#\"cuda\" refers to the defalut CUDA device that is being used by PyTorch\n",
    "cuda = torch.device(\"cuda\")\n",
    "\n",
    "#getting a specific device\n",
    "cuda0 = torch.device(\"cuda:0\")\n",
    "cuda1 = torch.device(\"cuda:1\")\n",
    "\n",
    "#creating a tensor on CPU\n",
    "x = torch.tensor([10,20])\n",
    "#creating a tensor on CUDA device\n",
    "x_default = torch.tensor([10,20], device=cuda)\n",
    "#creating a tensor on a specific CUDA device\n",
    "x_1 = torch.tensor([10,20], device=cuda1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a0166f92c009>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#if the tensor is already in CUDA memory and on the correct device no copy is preformed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#x is on CPU so now on CUDA using .cuda()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0my0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#x1 is on cuda1 now y0 is on copied x1 onto CUDA device 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "#.cuda() Retruns a copy of this object in CUDA memory\n",
    "#if the tensor is already in CUDA memory and on the correct device no copy is preformed\n",
    "\n",
    "y = x.cuda() #x is on CPU so now on CUDA using .cuda()\n",
    "\n",
    "y0 = x1.cuda() #x1 is on cuda1 now y0 is on copied x1 onto CUDA device 0\n",
    "\n",
    "# \"with\" can be used to change the cuda device that is running \n",
    "\n",
    "with torch.cuda.device[1]:\n",
    "    a = torch.tensor([10,20]) #CPU\n",
    "    a0 = torch.tensor([10,20], device=cuda0)#CUDA 0\n",
    "    a1 = torch.tensor([10,20], device=cuda) #CUDA 1\n",
    "\n",
    "b1 = a0.to(device=cuda1) #copies and changes the CUDA device\n",
    "\n",
    "#NOTE : Operations cannot be preformed on different CUDA devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gradients Using the Autograd Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent optimaztion - used train the models. The weights and biases of the individual neurons are determined during the training process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression - we want to minimize a loss function , in our case the least square error. The training occurs in gradient descent optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a surface that we want to find the lowest MSE which will be the best parameters (b and w) that give the least square error. y = bx + w. Gradient Descent goes down to find the lowest MSE this is an optimization algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by initializing w and b at random values and use algorithm to get to the lowest MSE, thus finding w and b that result in this value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Foward Pass and Backwards Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foward pass - all baises have been initialized to random values, the network will use the current weights to predict. The first model will be very poor. Differnce between actual and prediction. This error is used in the optimizer uses the error or loss function and tweaks the model parameters to minimize error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward pass - move backwards to optimize the model parameters to update all the parameters again. At every layer the model uses the gradient descent algorithm. Allows the weights and biases of the neurons to converge to their final values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Training using Autograd in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Autograd calulates gradients*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss = Y_predicted - Y_actual. A gradient is vector of partial derivates.\n",
    "The gradient is the partial derivative w.r.t the parameter W=(w1,w2,...,wN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find W such that the loss has the gradient has the lowest gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic differentiation - basis of calulating differenation computationally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back propagation is implemeted using a technique called reverse auto-differentiation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters(t+1) = Parameter(t) - learning_rate * gradient(theta t), think of t as the step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Automatic Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need 2 passes. Reverse-mode auto-differentiation.\n",
    "1)Foward step: Calucluate loss.\n",
    "2)Backwards step: Update parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Introduction to Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.Tensor([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2 = torch.Tensor([[7,8,9],[10,11,12]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".requires_grad - When True this tracks computations for a tensor in the foward phase and will calculate gradients for this tensor in the backward phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor = tensor1 * tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors have reference to the function that created this tensor, user-created tensors have no corresponding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MulBackward0 object at 0x0000021994C90948>\n"
     ]
    }
   ],
   "source": [
    "print(output_tensor.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MeanBackward0 object at 0x0000021994C90C08>\n"
     ]
    }
   ],
   "source": [
    "output_tensor = (tensor1 * tensor2).mean()\n",
    "print(output_tensor.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1667, 1.3333, 1.5000],\n",
      "        [1.6667, 1.8333, 2.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.grad.shape , tensor1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "new_tensor = tensor1 * 3\n",
    "print(new_tensor.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.,  6.,  9.],\n",
       "        [12., 15., 18.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_tensor = tensor([[ 3.,  6.,  9.],\n",
      "        [12., 15., 18.]])\n",
      "requires_grad for tensor = True\n",
      "requires_grad for tensor = False\n",
      "requires_grad for new_tensor = False\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    new_tensor = tensor1*3\n",
    "    print(\"new_tensor =\", new_tensor)\n",
    "    print(\"requires_grad for tensor =\", tensor1.requires_grad)\n",
    "    print(\"requires_grad for tensor =\", tensor2.requires_grad)\n",
    "    print(\"requires_grad for new_tensor =\", new_tensor.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Working with Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(t):\n",
    "    return t*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decorator so no gradient is needed, not enabled\n",
    "@torch.no_grad()\n",
    "def calculate_with_no_grad(t):\n",
    "    return t*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  6.],\n",
       "        [ 8., 10., 12.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tensor = calculate(tensor1)\n",
    "\n",
    "result_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tensor.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  6.],\n",
       "        [ 8., 10., 12.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tensor_no_grad = calculate_with_no_grad(tensor1)\n",
    "\n",
    "result_tensor_no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tensor_no_grad.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_tensor_no_grad = tensor([[ 3.,  6.,  9.],\n",
      "        [12., 15., 18.]])\n",
      "new_tensor_grad = tensor([[ 3.,  6.,  9.],\n",
      "        [12., 15., 18.]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#You can turn on and off grad with \"with\" embbedded\n",
    "with torch.no_grad():\n",
    "    new_tensor_no_grad = tensor1*3\n",
    "    print(\"new_tensor_no_grad =\", new_tensor_no_grad)\n",
    "    \n",
    "    with torch.enable_grad():\n",
    "        new_tensor_grad = tensor1 * 3\n",
    "        print(\"new_tensor_grad =\", new_tensor_grad)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_one = torch.tensor([[1.0,2.0],[3.0,4.0]],requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_two = torch.Tensor([[5,6],[7,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_one.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 6.],\n",
       "        [7., 8.]], requires_grad=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_two.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tensor = (tensor_one + tensor_two).mean()\n",
    "final_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tensor.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor_one.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tensor.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2500, 0.2500],\n",
      "        [0.2500, 0.2500]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_one.grad) #gradients calulated wrt to final tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient set to false\n",
    "detached_tensor = tensor_one.detach()\n",
    "detached_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Training a linear model with Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([[4.7],[2.4],[7.5],[7.1],[4.3],[7.816],\n",
    "                  [8.9],[5.2],[8.59],[2.1],[8],[10],\n",
    "                  [4.5],[6],[4]],dtype=np.float32)\n",
    "y_train = np.array([[2.6],[1.6],[3.09],[2.4],[2.4],[3.357],\n",
    "                  [2.6],[1.96],[3.53],[1.76],[3.2],[3.5],\n",
    "                  [1.6],[2.5],[2.2]], dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize =(12,8))\n",
    "\n",
    "plt.scatter(x_train,y_train,label=\"original data\",s=250,c=\"g\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad for X_train:  False\n",
      "requires_grad for Y_train:  False\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.from_numpy(x_train)\n",
    "Y_train = torch.from_numpy(y_train)\n",
    "\n",
    "print(\"requires_grad for X_train: \", X_train.requires_grad)\n",
    "print(\"requires_grad for Y_train: \", Y_train.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 1\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weights to our neuralnet\n",
    "w1 = torch.rand(input_size,hidden_size,requires_grad=True)\n",
    "w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Connection between hidden layer and final output\n",
    "w2 = torch.rand(hidden_size,output_size,requires_grad=True)\n",
    "w2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a98d3a371de5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#Foward pass through our NN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m#Mean squared error loss for linear regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "for iter in range(1,3000):\n",
    "    \n",
    "    #Foward pass through our NN\n",
    "    y_pred = X_train.mm(w1).mm(w2)\n",
    "    #Mean squared error loss for linear regression\n",
    "    loss = (y_pred-Y_train).pow(2).sum()\n",
    "    \n",
    "    #For every iteration of training\n",
    "    if iter % 50 == 0:\n",
    "        print(iter,loss.item())\n",
    "    \n",
    "    #Backward pass calculate gradient for model parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    #We dont need to enable grading tracking \n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 : tensor([[0.6068]], requires_grad=True)\n",
      "w2 : tensor([[0.6459]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"w1 :\",w1)\n",
    "print(\"w2 :\",w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.7000],\n",
       "        [ 2.4000],\n",
       "        [ 7.5000],\n",
       "        [ 7.1000],\n",
       "        [ 4.3000],\n",
       "        [ 7.8160],\n",
       "        [ 8.9000],\n",
       "        [ 5.2000],\n",
       "        [ 8.5900],\n",
       "        [ 2.1000],\n",
       "        [ 8.0000],\n",
       "        [10.0000],\n",
       "        [ 4.5000],\n",
       "        [ 6.0000],\n",
       "        [ 4.0000]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tensor = torch.from_numpy(x_train)\n",
    "x_train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8423],\n",
       "        [0.9407],\n",
       "        [2.9398],\n",
       "        [2.7830],\n",
       "        [1.6855],\n",
       "        [3.0636],\n",
       "        [3.4885],\n",
       "        [2.0383],\n",
       "        [3.3670],\n",
       "        [0.8231],\n",
       "        [3.1358],\n",
       "        [3.9197],\n",
       "        [1.7639],\n",
       "        [2.3518],\n",
       "        [1.5679]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_in_tensor = x_train_tensor.mm(w1).mm(w2)\n",
    "predicted_in_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8422655 ],\n",
       "       [0.9407314 ],\n",
       "       [2.9397855 ],\n",
       "       [2.7829971 ],\n",
       "       [1.6854771 ],\n",
       "       [3.0636487 ],\n",
       "       [3.4885454 ],\n",
       "       [2.0382512 ],\n",
       "       [3.3670347 ],\n",
       "       [0.82313997],\n",
       "       [3.1357713 ],\n",
       "       [3.919714  ],\n",
       "       [1.7638714 ],\n",
       "       [2.3518286 ],\n",
       "       [1.5678856 ]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = predicted_in_tensor.detach().numpy()\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize =(12,8))\n",
    "\n",
    "plt.scatter(x_train,y_train,label=\"original data\",s=250,c=\"g\")\n",
    "plt.plot(x_train,predicted,label=\"fitted line\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building Dynamic Computation Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Static vs Dynamic Computation Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural neworks are similar to directed-acyclic graphs. All of the computations and tensors in PyTorch together make up a directed-acyclic graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors are the nodes and the functions that mutate tensors are the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch computation graphs are **dynamic**, the graph is defined as it is executed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 approaches to Computation Graphs; Static(Tensorflow) and Dynamic(PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 types of building NN; Symbolic and Imperative, so you can first define computation then run or run computations are they defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PyTorch -> \"Define by Run\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TensorFlow -> \"Define, then Run\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(1,10)\n",
    "h = torch.randn(1,20)\n",
    "W_h = torch.randn(20,20,requires_grad=True)\n",
    "W_x = torch.randn(20,10,requires_grad=True)\n",
    "\n",
    "h_prod = torch.mm(W_h,h.t())\n",
    "x_prod = torch.mm(W_x,x.t())\n",
    "next_h = (h_prod+x_prod).tanh()\n",
    "loss = next_h.sum()\n",
    "loss.backward()\n",
    "#The above is built downwards and then the loss calulates the gradient upwards at every node (ie opperation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Static Graphs vs Dynamic Graphs comparison and visualizing NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorflow) (3.12.2)\n",
      "Requirement already satisfied: scipy==1.4.1 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorflow) (1.29.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from protobuf>=3.9.2->tensorflow) (46.4.0.post20200518)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.6.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: hiddenlayer in c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages (0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install graphviz\n",
    "!pip install hiddenlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: graphviz\n",
      "Version: 0.14.1\n",
      "Summary: Simple Python interface for Graphviz\n",
      "Home-page: https://github.com/xflr6/graphviz\n",
      "Author: Sebastian Bank\n",
      "Author-email: sebastian.bank@uni-leipzig.de\n",
      "License: MIT\n",
      "Location: c:\\users\\horacio\\anaconda3\\envs\\speck\\lib\\site-packages\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn(6)\n",
    "\n",
    "x = torch.tensor([10.0,10.0,10.0,10.0,10.0,10.0])\n",
    "\n",
    "b = torch.tensor(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0533,  0.9102, -0.0723,  1.0098,  0.2562,  0.8420])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating and executing the computation at the same time\n",
    "y = W*x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.4672, 12.1018,  2.2765, 13.0983,  5.5624, 11.4198])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5328,  9.1018, -0.7235, 10.0983,  2.5624,  8.4198])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.tensor(6)\n",
    "W2 = torch.tensor(6)\n",
    "W3 = torch.tensor(6)\n",
    "\n",
    "x1 = torch.tensor([2,2,2])\n",
    "x2 = torch.tensor([3,3,3])\n",
    "x3 = torch.tensor([5,5,5])\n",
    "\n",
    "b = torch.tensor(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6), tensor(6), tensor(6))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1,W2,W3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30, 30, 30])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermidiate_value = W1*x1 +W2*x2\n",
    "intermidiate_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([60, 60, 60])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_value =  W1*x1 + W2*x2 + W3*x3\n",
    "final_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to visualize neural networks\n",
    "import hiddenlayer as hl\n",
    "import graphviz\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'D:/Program Files (x86)/Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([[4.7],[2.4],[7.5],[7.1],[4.3],[7.816],\n",
    "                  [8.9],[5.2],[8.59],[2.1]],dtype=np.float32)\n",
    "y_train = np.array([[2.6],[1.6],[3.09],[2.4],[2.4],[3.357],\n",
    "                  [2.6],[1.96],[3.53],[1.76]], dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.from_numpy(x_train)\n",
    "Y_train = torch.from_numpy(y_train)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = 1 \n",
    "out = 1\n",
    "\n",
    "hid = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torch.nn.Sequential(torch.nn.Linear(inp,hid),\n",
    "                             torch.nn.Linear(hid,out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "(dot.exe:6040): Pango-WARNING **: couldn't load font \"Times Not-Rotated 10\", falling back to \"Sans Not-Rotated 10\", expect ugly output.\r\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"198pt\" height=\"116pt\"\r\n",
       " viewBox=\"0.00 0.00 198.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(72 80)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"#ffffff\" stroke=\"none\" points=\"-72,36 -72,-80 126,-80 126,36 -72,36\"/>\r\n",
       "<!-- 1201664841481757117 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>1201664841481757117</title>\r\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-44 0,-44 0,-0 54,-0 54,-44\"/>\r\n",
       "<text text-anchor=\"start\" x=\"14\" y=\"-28\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\r\n",
       "<text text-anchor=\"start\" x=\"35\" y=\"-7\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">x2</text>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<hiddenlayer.graph.Graph at 0x253b4633e08>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/graphviz-2.38/bin/'\n",
    "hl.build_graph(model1, torch.zeros([10,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "(dot.exe:13768): Pango-WARNING **: couldn't load font \"Times Not-Rotated 10\", falling back to \"Sans Not-Rotated 10\", expect ugly output.\r\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"574pt\" height=\"162pt\"\r\n",
       " viewBox=\"0.00 0.00 574.00 162.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(72 126)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"#ffffff\" stroke=\"none\" points=\"-72,36 -72,-126 502,-126 502,36 -72,36\"/>\r\n",
       "<!-- /outputs/5 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>/outputs/5</title>\r\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"62,-90 0,-90 0,-54 62,-54 62,-90\"/>\r\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-69\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Transpose</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/6 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>/outputs/6</title>\r\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"152,-90 98,-90 98,-54 152,-54 152,-90\"/>\r\n",
       "<text text-anchor=\"start\" x=\"110\" y=\"-69\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">MatMul</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/5&#45;&gt;/outputs/6 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>/outputs/5&#45;&gt;/outputs/6</title>\r\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M62.1242,-72C70.3206,-72 79.2835,-72 87.7797,-72\"/>\r\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"87.8288,-75.5001 97.8288,-72 87.8288,-68.5001 87.8288,-75.5001\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/7 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>/outputs/7</title>\r\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"246,-90 192,-90 192,-54 246,-54 246,-90\"/>\r\n",
       "<text text-anchor=\"start\" x=\"211\" y=\"-69\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Add</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/6&#45;&gt;/outputs/7 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>/outputs/6&#45;&gt;/outputs/7</title>\r\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M152.117,-72C161.343,-72 171.891,-72 181.802,-72\"/>\r\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"181.817,-75.5001 191.817,-72 181.817,-68.5001 181.817,-75.5001\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/9 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>/outputs/9</title>\r\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"340,-63 286,-63 286,-27 340,-27 340,-63\"/>\r\n",
       "<text text-anchor=\"start\" x=\"298\" y=\"-42\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">MatMul</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/7&#45;&gt;/outputs/9 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>/outputs/7&#45;&gt;/outputs/9</title>\r\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M246.117,-64.3351C255.441,-61.599 266.113,-58.4668 276.114,-55.5316\"/>\r\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"277.208,-58.8585 285.817,-52.6841 275.236,-52.1418 277.208,-58.8585\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/8 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>/outputs/8</title>\r\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"250,-36 188,-36 188,-0 250,-0 250,-36\"/>\r\n",
       "<text text-anchor=\"start\" x=\"196\" y=\"-15\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Transpose</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/8&#45;&gt;/outputs/9 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>/outputs/8&#45;&gt;/outputs/9</title>\r\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M250.124,-26.8408C258.411,-29.2727 267.481,-31.9345 276.06,-34.4523\"/>\r\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"275.248,-37.8616 285.829,-37.3193 277.219,-31.1449 275.248,-37.8616\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/10 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>/outputs/10</title>\r\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"430,-63 376,-63 376,-27 430,-27 430,-63\"/>\r\n",
       "<text text-anchor=\"start\" x=\"395\" y=\"-42\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Add</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/9&#45;&gt;/outputs/10 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>/outputs/9&#45;&gt;/outputs/10</title>\r\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M340.403,-45C348.393,-45 357.311,-45 365.824,-45\"/>\r\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"365.919,-48.5001 375.919,-45 365.919,-41.5001 365.919,-48.5001\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<hiddenlayer.graph.Graph at 0x253b4645b08>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl.build_graph(model1, torch.zeros([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = torch.nn.Sequential(torch.nn.Linear(inp,hid),\n",
    "                             torch.nn.Linear(hid,hid),\n",
    "                             torch.nn.Sigmoid(),\n",
    "                             torch.nn.Linear(hid,out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "(dot.exe:6644): Pango-WARNING **: couldn't load font \"Times Not-Rotated 10\", falling back to \"Sans Not-Rotated 10\", expect ugly output.\r\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"378pt\" height=\"116pt\"\r\n",
       " viewBox=\"0.00 0.00 378.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(72 80)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"#ffffff\" stroke=\"none\" points=\"-72,36 -72,-80 306,-80 306,36 -72,36\"/>\r\n",
       "<!-- /outputs/9 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>/outputs/9</title>\r\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"144,-40 90,-40 90,-4 144,-4 144,-40\"/>\r\n",
       "<text text-anchor=\"start\" x=\"100\" y=\"-19\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Sigmoid</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/10 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>/outputs/10</title>\r\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"234,-40 180,-40 180,-4 234,-4 234,-40\"/>\r\n",
       "<text text-anchor=\"start\" x=\"194\" y=\"-19\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/9&#45;&gt;/outputs/10 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>/outputs/9&#45;&gt;/outputs/10</title>\r\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M144.403,-22C152.393,-22 161.311,-22 169.824,-22\"/>\r\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"169.919,-25.5001 179.919,-22 169.919,-18.5001 169.919,-25.5001\"/>\r\n",
       "</g>\r\n",
       "<!-- 9258164284241592455 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>9258164284241592455</title>\r\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-44 0,-44 0,-0 54,-0 54,-44\"/>\r\n",
       "<text text-anchor=\"start\" x=\"14\" y=\"-28\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\r\n",
       "<text text-anchor=\"start\" x=\"35\" y=\"-7\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">x2</text>\r\n",
       "</g>\r\n",
       "<!-- 9258164284241592455&#45;&gt;/outputs/9 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>9258164284241592455&#45;&gt;/outputs/9</title>\r\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M54.4029,-22C62.3932,-22 71.3106,-22 79.8241,-22\"/>\r\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.919,-25.5001 89.919,-22 79.919,-18.5001 79.919,-25.5001\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<hiddenlayer.graph.Graph at 0x253b4646508>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl.build_graph(model2, torch.zeros([10,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "(dot.exe:8320): Pango-WARNING **: couldn't load font \"Times Not-Rotated 10\", falling back to \"Sans Not-Rotated 10\", expect ugly output.\r\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"574pt\" height=\"162pt\"\r\n",
       " viewBox=\"0.00 0.00 574.00 162.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(72 126)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"#ffffff\" stroke=\"none\" points=\"-72,36 -72,-126 502,-126 502,36 -72,36\"/>\r\n",
       "<!-- /outputs/5 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>/outputs/5</title>\r\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"62,-90 0,-90 0,-54 62,-54 62,-90\"/>\r\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-69\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Transpose</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/6 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>/outputs/6</title>\r\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"152,-90 98,-90 98,-54 152,-54 152,-90\"/>\r\n",
       "<text text-anchor=\"start\" x=\"110\" y=\"-69\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">MatMul</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/5&#45;&gt;/outputs/6 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>/outputs/5&#45;&gt;/outputs/6</title>\r\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M62.1242,-72C70.3206,-72 79.2835,-72 87.7797,-72\"/>\r\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"87.8288,-75.5001 97.8288,-72 87.8288,-68.5001 87.8288,-75.5001\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/7 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>/outputs/7</title>\r\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"246,-90 192,-90 192,-54 246,-54 246,-90\"/>\r\n",
       "<text text-anchor=\"start\" x=\"211\" y=\"-69\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Add</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/6&#45;&gt;/outputs/7 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>/outputs/6&#45;&gt;/outputs/7</title>\r\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M152.117,-72C161.343,-72 171.891,-72 181.802,-72\"/>\r\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"181.817,-75.5001 191.817,-72 181.817,-68.5001 181.817,-75.5001\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/9 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>/outputs/9</title>\r\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"340,-63 286,-63 286,-27 340,-27 340,-63\"/>\r\n",
       "<text text-anchor=\"start\" x=\"298\" y=\"-42\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">MatMul</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/7&#45;&gt;/outputs/9 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>/outputs/7&#45;&gt;/outputs/9</title>\r\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M246.117,-64.3351C255.441,-61.599 266.113,-58.4668 276.114,-55.5316\"/>\r\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"277.208,-58.8585 285.817,-52.6841 275.236,-52.1418 277.208,-58.8585\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/8 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>/outputs/8</title>\r\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"250,-36 188,-36 188,-0 250,-0 250,-36\"/>\r\n",
       "<text text-anchor=\"start\" x=\"196\" y=\"-15\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Transpose</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/8&#45;&gt;/outputs/9 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>/outputs/8&#45;&gt;/outputs/9</title>\r\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M250.124,-26.8408C258.411,-29.2727 267.481,-31.9345 276.06,-34.4523\"/>\r\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"275.248,-37.8616 285.829,-37.3193 277.219,-31.1449 275.248,-37.8616\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/10 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>/outputs/10</title>\r\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"430,-63 376,-63 376,-27 430,-27 430,-63\"/>\r\n",
       "<text text-anchor=\"start\" x=\"395\" y=\"-42\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Add</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/9&#45;&gt;/outputs/10 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>/outputs/9&#45;&gt;/outputs/10</title>\r\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M340.403,-45C348.393,-45 357.311,-45 365.824,-45\"/>\r\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"365.919,-48.5001 375.919,-45 365.919,-41.5001 365.919,-48.5001\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<hiddenlayer.graph.Graph at 0x253b4650f88>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl.build_graph(model1, torch.zeros([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Horacio\\Anaconda3\\envs\\speck\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(6, name=\"var_W\")\n",
    "x = tf.placeholder(tf.int32, shape = [3], name = \"x\")\n",
    "b = tf.constant(3, name = \"constant_b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'var_W_1:0' shape=() dtype=int32_ref>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W #Info about the value but not the value, because it is static until execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'x_1:0' shape=(3,) dtype=int32>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'constant_b_1:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = W*x + b #here we define the computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(3,) dtype=int32>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W*x+b = [ 63 123 183]\n"
     ]
    }
   ],
   "source": [
    "#A session is a bridge between c++ and python code to execute tensorflow\n",
    "with tf.Session() as sess:\n",
    "    #Here it inializes the W param\n",
    "    sess.run(init)\n",
    "    \n",
    "    #Here feed_dict feeds into y which defined above\n",
    "    y_result = sess.run(y, feed_dict = {x:[10, 20, 30]})\n",
    "    \n",
    "    print(\"W*x+b =\", y_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(\"./graphs\",sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Operation 'var_W/initial_value' type=Const>, <tf.Operation 'var_W' type=VariableV2>, <tf.Operation 'var_W/Assign' type=Assign>, <tf.Operation 'var_W/read' type=Identity>, <tf.Operation 'x' type=Placeholder>, <tf.Operation 'constant_b' type=Const>, <tf.Operation 'var_W_1/initial_value' type=Const>, <tf.Operation 'var_W_1' type=VariableV2>, <tf.Operation 'var_W_1/Assign' type=Assign>, <tf.Operation 'var_W_1/read' type=Identity>, <tf.Operation 'x_1' type=Placeholder>, <tf.Operation 'constant_b_1' type=Const>, <tf.Operation 'mul' type=Mul>, <tf.Operation 'add' type=AddV2>, <tf.Operation 'init' type=NoOp>]\n"
     ]
    }
   ],
   "source": [
    "print(graph.get_operations())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this to visualize the graph created on command line:\n",
    "tensorboard --logdir=graphs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
